<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.7.1 by Michael Rose
  Copyright 2017 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->









<title>Crawling web pages using Python and Scrapy - Tutorial  Thavanathan</title>




<meta name="description" content="In this post, let us walk through how we can crawl web pages using Scrapy.">




<meta name="author" content="Thavanathan Thangaraj">

<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Thavanathan">
<meta property="og:title" content="Crawling web pages using Python and Scrapy - Tutorial">


  <link rel="canonical" href="https://www.thavanathan.com/python/crawling-web-pages-with-scrapy/">
  <meta property="og:url" content="https://www.thavanathan.com/python/crawling-web-pages-with-scrapy/">



  <meta property="og:description" content="In this post, let us walk through how we can crawl web pages using Scrapy.">





















  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2015-06-02T14:30:00+05:30">














<!-- end SEO -->


<link href="https://www.thavanathan.com/feed.xml" type="application/atom+xml" rel="alternate" title="Thavanathan Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="https://www.thavanathan.com/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->
  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="https://www.thavanathan.com/">Thavanathan</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item"><a href="https://www.thavanathan.com/about/">About</a></li>
          
        </ul>
        <button type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    


  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="http://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
          <a href="https://www.thavanathan.com/" itemprop="item"><span itemprop="name">Home</span></a>
          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">/</span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
          <a href="https://www.thavanathan.com/categories/python" itemprop="item"><span itemprop="name">Python</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">/</span>
      
    
      
      
        <li class="current">Crawling web pages using Python and Scrapy - Tutorial</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  

<div itemscope itemtype="http://schema.org/Person">

  

  <div class="author__content">
    <h3 class="author__name" itemprop="name">Thavanathan Thangaraj</h3>
    
      <p class="author__bio" itemprop="description">
        Full stack developer. Python, Django enthusiast and teacher
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      
        <li>
          <a href="http://www.thavanathan.com" itemprop="url">
            <i class="fa fa-fw fa-chain" aria-hidden="true"></i> Website
          </a>
        </li>
      

      

      

      
        <li>
          <a href="https://twitter.com/pythavan" itemprop="sameAs">
            <i class="fa fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fa fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Crawling web pages using Python and Scrapy - Tutorial">
    <meta itemprop="description" content="In this post, let us walk through how we can crawl web pages using Scrapy.">
    <meta itemprop="datePublished" content="June 02, 2015">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Crawling web pages using Python and Scrapy - Tutorial
</h1>
          
            <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  3 minute read
</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>In this post, let us walk through how we can crawl web pages using <a href="http://scrapy.org/">Scrapy</a>.</p>

<p>For this tutorial, we will download all the excerpts and ebooks available in https://www.goodreads.com/ebooks?sort=popular_books. This page is paginated. Let’s download books from first page only. At the end of this post, you will know how to follow and crawl other pages too.</p>

<p>First lets create a python virtual environment called goodreads.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">mkvirtualenv goodreads
workon goodreads</code></pre></figure>

<p>To know more about how mkvirtualenv and workon commands work, visit and install <a href="https://virtualenvwrapper.readthedocs.org/">virtualenvwrapper</a></p>

<p>Now, lets install scrapy.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">pip install scrapy</code></pre></figure>

<p>After installing, lets create a new project.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">scrapy startproject goodreads
<span class="nb">cd </span>goodreads</code></pre></figure>

<p>This will create the following directory structure.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── goodreads
│   ├── __init__.py
│   ├── items.py
│   ├── pipelines.py
│   ├── settings.py
│   └── spiders
│       └── __init__.py
└── scrapy.cfg
</code></pre></div></div>

<p>For this tutorial, we will only touch spiders directory, settings.py, items.py. Spider directory will contain all the spiders, otherwise called crawlers. settings.py will have project related settings. items.py will define your models. Model or Item is a definition of a object that you are going to crawl. For example, if we crawl stock details from a page, we can define a item like the one below</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">Stock</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="n">company_name</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">price</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span></code></pre></figure>

<p>For our project we will create a item with following field. open goodreads/items.py and add following lines.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">GoodreadsItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="n">file_name</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span></code></pre></figure>

<p>We will save downloaded path of the document in file_name field.</p>

<p>Now lets create a spider to crawl books. Run the following command in terminal.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">    scrapy genspider goodread_spider http://www.goodreads.com/ebooks?page<span class="o">=</span>1&amp;sort<span class="o">=</span>popular_books <span class="nt">-t</span> crawl</code></pre></figure>

<p>This will generate the spider file called goodreads_spider. A spider is somethings that crawls web pages and follows the links on that page to crawl other pages. Spider itself will not follow links available in a page. We have to define rules to follow links.</p>

<p>Open goodreads/spiders/goodread_spider.py</p>

<p>Let’s adjust some variables according to out site.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">allowed_domains <span class="o">=</span> <span class="o">[</span><span class="s1">'www.goodreads.com'</span>, <span class="s1">'s3.amazonaws.com'</span><span class="o">]</span>
start_urls <span class="o">=</span> <span class="o">[</span><span class="s1">'http://www.goodreads.com/ebooks?page=1&amp;sort=popular_books'</span><span class="o">]</span></code></pre></figure>

<p>s3.amazonaws.com is where goodreads books are hosted. So we have to add this domain to allowed_domains list.</p>

<p>Now lets add a rule to follow and download ebook. Edit the rule defined to match with following line.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">rules</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">Rule</span><span class="p">(</span><span class="n">LinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="s">r'ebooks/download/.*'</span><span class="p">),</span> <span class="n">callback</span><span class="o">=</span><span class="s">'parse_item'</span><span class="p">,</span> <span class="n">follow</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
<span class="p">)</span></code></pre></figure>

<p>follow=True means follow them if any other links present in the crawled page. Even if follow is true, it should match any of defined rules. ebook/download/<item_id> will actually return ebook document. It may be any file including pdf, epub, mobi and zip.</item_id></p>

<p>Every time an item is fetched our callback function parse_item will called with the response object.</p>

<p>Lets make some changes in parse_item function in the same file to save our downloaded books. Edit the parse_item function to match with the following lines.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">goodreads.items</span> <span class="kn">import</span> <span class="n">GoodreadsItem</span>
<span class="kn">from</span> <span class="nn">scrapy</span> <span class="kn">import</span> <span class="n">log</span>

<span class="k">def</span> <span class="nf">parse_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">response</span><span class="o">.</span><span class="n">headers</span><span class="p">[</span><span class="s">'Content-Type'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'text/html; charset=utf-8'</span><span class="p">:</span>
        <span class="n">item</span> <span class="o">=</span> <span class="n">GoodreadsItem</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'file_name'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'/Users/thavan/learnspace/ebooks/'</span> <span class="o">+</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">'/'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s">'file_name'</span><span class="p">],</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">msg</span><span class="p">(</span><span class="s">'Path {0}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s">'file_name'</span><span class="p">]),</span> <span class="n">level</span><span class="o">=</span><span class="n">log</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">item</span></code></pre></figure>

<p>We have added an if condition to make sure we download only books not html pages. If it is text/html we omit the response else we save the response in a file.</p>

<p>Now lets run the crawler</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">scrapy crawl goodread_spider</code></pre></figure>

<p>As mentioned earlier, this spider will crawl books in only first page. To crawl all the books in different pages, we have to add one more rule. Add the below line to Rules tuple in goodread_spider.py</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">Rule<span class="o">(</span>LinkExtractor<span class="o">(</span><span class="nv">allow</span><span class="o">=</span>r<span class="s1">'ebooks\?page=\d+&amp;sort=popular_books'</span><span class="o">)</span>, <span class="nv">follow</span><span class="o">=</span>True<span class="o">)</span>,</code></pre></figure>

<p>That’s it for now. Use settings.py to change project related settings. User agent can be changed in settings.py. Open goodreads/settings.py and change the USER_AGENT. You can also set delay between every page request. DOWNLOAD_DELAY = 0.25 will set 250ms delay before sending a request.</p>

<p>As a final note, crawling a website going to give extra load to server. The example given in this tutorial is only for educational purpose. Crawl responsibly by identifying yourself (and your website) on the user-agent.</p>


        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="https://www.thavanathan.com/tags/crawling" class="page__taxonomy-item" rel="tag">crawling</a><span class="sep">, </span>
    
      
      
      <a href="https://www.thavanathan.com/tags/scrapy" class="page__taxonomy-item" rel="tag">scrapy</a>
    
    </span>
  </p>




  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="https://www.thavanathan.com/categories/python" class="page__taxonomy-item" rel="tag">Python</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Updated:</strong> <time datetime="2015-06-02T14:30:00+05:30">June 02, 2015</time></p>
        
      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=Crawling+web+pages+using+Python+and+Scrapy+-+Tutorial%20https%3A%2F%2Fwww.thavanathan.com%2Fpython%2Fcrawling-web-pages-with-scrapy%2F" class="btn btn--twitter" title="Share on Twitter"><i class="fa fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thavanathan.com%2Fpython%2Fcrawling-web-pages-with-scrapy%2F" class="btn btn--facebook" title="Share on Facebook"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://plus.google.com/share?url=https%3A%2F%2Fwww.thavanathan.com%2Fpython%2Fcrawling-web-pages-with-scrapy%2F" class="btn btn--google-plus" title="Share on Google Plus"><i class="fa fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.thavanathan.com%2Fpython%2Fcrawling-web-pages-with-scrapy%2F" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fa fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="https://www.thavanathan.com/python/static-site-generators/" class="pagination--pager" title="Static Site Generators
">Previous</a>
    
    
      <a href="https://www.thavanathan.com/python/python-list-comprehensions-and-generator-expressions/" class="pagination--pager" title="Python List Comprehensions and generator expressions
">Next</a>
    
  </nav>

    </div>

    
      <div class="page__comments">
  
  
      <section id="static-comments">
        
          <!-- Start static comments -->
          <div class="js-comments">
            
          </div>
          <!-- End static comments -->

          <!-- Start new comment form -->
          <div class="page__comments-form">
            <h4 class="page__comments-title">Leave a Comment</h4>
            <p class="small">Your email address will not be published. Required fields are marked <span class="required">*</span></p>
            <form id="new_comment" class="page__comments-form js-form form" method="post" action="https://api.staticman.net/v2/entry/thavan/www.thavanathan.com/master/comments">
              <div class="form__spinner">
                <i class="fa fa-spinner fa-spin fa-3x fa-fw"></i>
                <span class="sr-only">Loading...</span>
              </div>

              <div class="form-group">
                <label for="comment-form-message">Comment <small class="required">*</small></label>
                <textarea type="text" rows="3" id="comment-form-message" name="fields[message]" tabindex="1"></textarea>
                <div class="small help-block"><a href="https://daringfireball.net/projects/markdown/">Markdown is supported.</a></div>
              </div>
              <div class="form-group">
                <label for="comment-form-name">Name <small class="required">*</small></label>
                <input type="text" id="comment-form-name" name="fields[name]" tabindex="2" />
              </div>
              <div class="form-group">
                <label for="comment-form-email">Email address <small class="required">*</small></label>
                <input type="email" id="comment-form-email" name="fields[email]" tabindex="3" />
              </div>
              <div class="form-group">
                <label for="comment-form-url">Website (optional)</label>
                <input type="url" id="comment-form-url" name="fields[url]" tabindex="4"/>
              </div>
              <div class="form-group hidden" style="display: none;">
                <input type="hidden" name="options[slug]" value="crawling-web-pages-with-scrapy">
                <label for="comment-form-location">Not used. Leave blank if you are a human.</label>
                <input type="text" id="comment-form-location" name="fields[hidden]" autocomplete="off"/>
                <input type="hidden" name="options[reCaptcha][siteKey]" value="">
                <input type="hidden" name="options[reCaptcha][secret]" value="">
              </div>
              <!-- Start comment form alert messaging -->
              <p class="hidden js-notice">
                <strong class="js-notice-text"></strong>
              </p>
              <!-- End comment form alert messaging -->
              <div class="form-group">
                <div class="g-recaptcha" data-sitekey=""></div>
              </div>
              <div class="form-group">
                <button type="submit" id="comment-form-submit" tabindex="5" class="btn btn--primary btn--large">Submit Comment</button>
              </div>
            </form>
          </div>
          <!-- End new comment form -->
          
        
      </section>
    
</div>
    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="https://www.thavanathan.com/python/understand-web-programming-with-python/" rel="permalink">Understanding web programming with Python 1
</a>
      
    </h2>
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  3 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Web programming or web development is an art of developing web sites. It’s a broader term. There are numerous number of web frameworks out there to easily ge...</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="https://www.thavanathan.com/python/python-save-memory-usage-with-slots/" rel="permalink">Reduce memory usage in Python using slots
</a>
      
    </h2>
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  3 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">slots is a kind of Python magic that reduces memory usage of a program. It’s useful only when we have a 
lot objects with fixed number of attributes. For exa...</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="https://www.thavanathan.com/python/python-list-comprehensions-and-generator-expressions/" rel="permalink">Python List Comprehensions and generator expressions
</a>
      
    </h2>
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  3 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Comprehensions are one of the prominent features of Python. Once you understand them, it helps avoiding lots of 
redundant and repetitive code. It helps crea...</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="https://www.thavanathan.com/python/static-site-generators/" rel="permalink">Static Site Generators
</a>
      
    </h2>
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  3 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Static site generators are tools that generates static sites i.e. pure html websites without backend data processing, session management or user authenticati...</p>
  </article>
</div>
        
      </div>
    </div>
  
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
    
    
    
    
    
    <li><a href="https://www.thavanathan.com/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2017 Thavanathan. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="https://www.thavanathan.com/assets/js/main.min.js"></script>







    
  <script>
    (function ($) {
    var $comments = $('.js-comments');

    $('#new_comment').submit(function () {
      var form = this;

      $(form).addClass('disabled');
      $('#comment-form-submit').html('<i class="fa fa-spinner fa-spin fa-fw"></i> Loading...');

      $.ajax({
        type: $(this).attr('method'),
        url: $(this).attr('action'),
        data: $(this).serialize(),
        contentType: 'application/x-www-form-urlencoded',
        success: function (data) {
          $('#comment-form-submit').html('Submitted');
          $('.page__comments-form .js-notice').removeClass('notice--danger');
          $('.page__comments-form .js-notice').addClass('notice--success');
          showAlert('Thanks for your comment! It will show on the site once it has been approved.');
        },
        error: function (err) {
          console.log(err);
          $('#comment-form-submit').html('Submit Comment');
          $('.page__comments-form .js-notice').removeClass('notice--success');
          $('.page__comments-form .js-notice').addClass('notice--danger');
          showAlert('Sorry, there was an error with your submission. Please make sure all required fields have been completed and try again.');
          $(form).removeClass('disabled');
        }
      });

      return false;
    });

    function showAlert(message) {
      $('.page__comments-form .js-notice').removeClass('hidden');
      $('.page__comments-form .js-notice-text').html(message);
    }
  })(jQuery);
  </script>

  



  </body>
</html>